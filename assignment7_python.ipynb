{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datasciencedegree.wisconsin.edu/wp-content/themes/data-gulp/images/logo.svg\" width=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. Introduction\n",
    "\n",
    "The first problem has you write some functions in order to be able to do statistics on arbitrary text.  First, we'll write a function determining the length of each word in a given sentence.  Second, we'll apply that function to some given text.  Third, we'll use it to solve a larger problem: determine properties of each sentence in a Jane Austin book.\n",
    "\n",
    "## Problem 1(a).  Word length\n",
    "\n",
    "ðŸŽ¯ Write a function called ```word_length_list()``` which takes a string and returns a list with the length of each word in the string.  \n",
    "\n",
    "For each word, count the number of English, alphanumeric characters.  Words are defined as text separated by spaces. Your function should ignore punctuation.  For example, ```word_length_list(\"Haven't you eaten 8 oranges today?\")``` should return ```[6,3,5,1,7,5]```.  \n",
    "\n",
    "* Call or create other functions as necessary to organize your work.\n",
    "* Write your own code to do this from first principles.  This means using Python built-in functions for splitting text, checking whether characters are punctuation, etc.  \n",
    "* Do *not* use Python packages (like nltk) or code directly copied from online resources (such as regular expressions for splitting text) in order to divide sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Havent you eaten 8 oranges today\n",
      "[6, 3, 5, 1, 7, 5]\n",
      "Havent you eaten 8 oranges today\n"
     ]
    }
   ],
   "source": [
    "def word_length_list(in_text):\n",
    "    import string\n",
    "\n",
    "    # remove punctuation\n",
    "    for p in string.punctuation:\n",
    "        in_text = in_text.replace(p,\"\")\n",
    "    \n",
    "    print(in_text)\n",
    "    \n",
    "    # split the text into a list\n",
    "    words = in_text.split()\n",
    "    \n",
    "    # define output list\n",
    "    count_out = []\n",
    "\n",
    "    # for each word in the line return the length\n",
    "    for word in words:\n",
    "        count_out.append(len(word))\n",
    "    \n",
    "    return count_out\n",
    "                  \n",
    "    \n",
    "print(word_length_list(\"Haven't you eaten 8 oranges today?\") )\n",
    "\n",
    "assert(word_length_list(\"Haven't you eaten 8 oranges today?\")==[6,3,5,1,7,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Havent you eaten 8 oranges today\n"
     ]
    }
   ],
   "source": [
    "# this line will run clean when you have solved the problem.\n",
    "assert(word_length_list(\"Haven't you eaten 8 oranges today?\")==[6,3,5,1,7,5])\n",
    "# be sure to restart the kernel and run all cells before committing.  \n",
    "# this ensures the most recent state is what you think it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1(b).  Application -- \"A Mourner.\"\n",
    "\n",
    "The text below is an anonymous essay published in The Boston Gazette and Country Journal on January 8, 1770. \n",
    "\n",
    ">The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Fatherâ€™s House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble Cause--Whose manly Spirit (after this Accident happened) appearâ€™d in his discreet Answers to his Doctor, his Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of bodily Pain; and with which he met the King of Terrors.  These Things, together with the several heroic Pieces found in his Pocket, particularly Wolfeâ€™s Summit of human Glory, gives Reason to think he had a martial Genius, and would have made a clever Man.\n",
    "\t\t\t\t\t\n",
    "> A Mourner.\n",
    "\n",
    "(Source:  Michael Sullivan, _Statistics:  Informed Decisions Using Data_, 4th ed.  p. 188-189.)\n",
    "\n",
    "ðŸŽ¯ Use your function ```word_length_list()``` from 1(a) to find the length of each word in \"A Mourner\". (Note that your output should end in . . ., 3, 1, 7].)\n",
    "\n",
    "###### Notes\n",
    "\n",
    "* check out `%pprint`.  It turns off printing each list element on a separate row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant will be sufficient Reason for your Notifying the Public that he will be buried from his Fatherâ€™s House in Frogg Lane opposite LibertyTree on Monday next when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble CauseWhose manly Spirit after this Accident happened appearâ€™d in his discreet Answers to his Doctor his Thanks to the Clergymen who prayed with him and Parents and while he underwent the greatest Distress of bodily Pain and with which he met the King of Terrors These Things together with the several heroic Pieces found in his Pocket particularly Wolfeâ€™s Summit of human Glory gives Reason to think he had a martial Genius and would have made a clever Man A Mourner\n",
      "[3, 7, 8, 3, 7, 3, 3, 6, 2, 3, 3, 2, 3, 4, 3, 8, 10, 2, 3, 3, 7, 4, 2, 10, 6, 3, 4, 9, 3, 6, 4, 2, 4, 2, 6, 4, 3, 8, 5, 2, 5, 4, 8, 11, 2, 6, 4, 4, 3, 3, 7, 2, 7, 3, 4, 2, 11, 2, 6, 5, 4, 8, 2, 3, 7, 2, 4, 6, 4, 3, 5, 6, 2, 3, 5, 10, 5, 6, 5, 4, 8, 8, 8, 2, 3, 8, 7, 2, 3, 6, 3, 6, 2, 3, 9, 3, 6, 4, 3, 3, 7, 3, 5, 2, 9, 3, 8, 8, 2, 6, 4, 3, 4, 5, 2, 3, 3, 4, 2, 7, 5, 6, 8, 4, 3, 7, 6, 6, 5, 2, 3, 6, 12, 7, 6, 2, 5, 5, 5, 6, 2, 5, 2, 3, 1, 7, 6, 3, 5, 4, 4, 1, 6, 3, 1, 7]\n"
     ]
    }
   ],
   "source": [
    "MOURNER_TEXT = \"The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Fatherâ€™s House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble Cause--Whose manly Spirit (after this Accident happened) appearâ€™d in his discreet Answers to his Doctor, his Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of bodily Pain; and with which he met the King of Terrors. These Things, together with the several heroic Pieces found in his Pocket, particularly Wolfeâ€™s Summit of human Glory, gives Reason to think he had a martial Genius, and would have made a clever Man. A Mourner.\"\n",
    "\n",
    "print(word_length_list(MOURNER_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1(c). _Pride and Prejudice_.\n",
    "\n",
    "This problem is a bit bigger than parts (a) and (b), and requires some bigger thinking.  You'll have to write loops and possibly list comprehensions to solve it!\n",
    "\n",
    "ðŸŽ¯ Create a function \n",
    "```collect_statistics``` \n",
    "to count the number of words and mean length of words in each sentence of *Pride and Prejudice*.  We have provided `pride.txt` file in the repo, which is available without restrictions from [Project Gutenberg](https://www.gutenberg.org/).  \n",
    "\n",
    "###### Suggestions\n",
    "\n",
    "* You should use the `word_length_list` function from 1(a) in your solution.\n",
    "* Create additional functions as necessary to organize your work.\n",
    "\n",
    "Before you start programming, I suggest you compute the answers by hand, for the first few sentences of *Pride and Prejudice*.  Be sure you go far enough in the file to encounter a few anomalies!  This will give you a sense of\n",
    "  * How to solve the problem using a computer.  Make the computer do what you did!  \n",
    "  * What the answer looks like, in that you will know the first few terms in the data set you are constructing.\n",
    "\n",
    "###### Requirements and notes\n",
    "\n",
    "\n",
    "* A sentence ends with a period, exclamation point, or question mark. A hyphen, dash, or apostrophe does not end a sentence. Quotation marks do not end a sentence. But also, some periods do not end sentences. For example, Mrs., Mr., Dr., Fr., Jr., St., are all commonly occurring abbreviations that almost never end sentences, and they occur enough in Pride and Prejudice that you need to deal with them or your averages will be impacted significantly. An ellipsis sometimes ends a sentence and sometimes does not, but for this assignment you may assume an ellipsis ends a sentence (but note it does not end 3 sentences!) \n",
    "* Do *not* use Python packages (like nltk) or code directly copied from online resources (such as regular expressions for splitting text) in order to divide sentences. Write your own code to do this from first principles.\n",
    "* The mean length of words in the sample sentence from 1(a) ```\"Haven't you eaten 8 oranges today?\"``` is 4.5.\n",
    "\n",
    "###### Output\n",
    "\n",
    "* Include comments to explain the purpose and arguments of each function you create.\n",
    "* Save your result as a ```.csv``` file and include it with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Open File with utf-8\n",
    "def read_file(in_name):\n",
    "    with open(in_name,'r',encoding=\"utf-8\") as f:\n",
    "        out_data = f.read()\n",
    "    f.closed\n",
    "    return out_data\n",
    "\n",
    "#Write File \n",
    "def write_file(in_name,in_data):\n",
    "    in_data_str = str(in_data)                    # Convert list to a String.\n",
    "    with open(in_name,'w',encoding=\"utf-8\") as f:\n",
    "        out_data = f.write(in_data_str)\n",
    "    f.closed\n",
    "    return\n",
    "\n",
    "#Remove period at the end of Abbreviations such as Mr. Mrs. Dr. and replace with Mr Mrs Dr\n",
    "def remove_abbreviations(in_data):\n",
    "    out_data = in_data.replace(\"Mrs.\",\"Mrs\").replace(\"Mr.\",\"Mr\").replace(\"Dr.\",\"Dr\").replace(\"Fr.\",\"Fr\").replace(\"Jr.\",\"Jr\").replace(\"St.\",\"St\")\n",
    "    return out_data\n",
    "\n",
    "#Remove punctuation such as ' - ,  and replace with a space\n",
    "def remove_bad_punct(in_data):\n",
    "    out_data = in_data.replace(',',\" \").replace(';',\" \").replace('-',\" \").replace('\"',\" \").replace('â€œ',\" \").replace('â€',\" \").replace('_',\" \").replace(':',\" \") \n",
    "    return out_data\n",
    "\n",
    "#Remove good punctuation such as ? ! and replace with a .\n",
    "def remove_good_punct(in_data):\n",
    "    out_data = in_data.replace('?',\".\").replace('!',\".\").replace('...',\".\")\n",
    "    return out_data\n",
    "\n",
    "#Remove white noise in the file.\n",
    "def remove_bad_lines(in_data):\n",
    "    out_data = in_data.replace('\\n',\" \")\n",
    "    return out_data\n",
    "\n",
    "#Remove the Title and Chapters in the file.\n",
    "def remove_title(in_data):\n",
    "    out_data = in_data.replace('PRIDE AND PREJUDICE',\"\").replace('By Jane Austen',\"\").replace('Chapter',\"\")\n",
    "    return out_data\n",
    "\n",
    "#Split the text into sentences and break by period '.'\n",
    "def split_into_sentences(in_data):\n",
    "    out_data = in_data.split('.')\n",
    "    return out_data\n",
    "\n",
    "#Split the words of each sentence into a separate list. \n",
    "def split_into_words(in_data):\n",
    "    per_sentence = []\n",
    "    for sentence in in_data:\n",
    "        per_sentence.append(sentence.split())\n",
    "    return per_sentence\n",
    "\n",
    "#Create the list of Number of Words and Average Length.\n",
    "def word_length_list2(in_data):\n",
    "    data = []\n",
    "    for i, words_in_sent in enumerate(in_data):                              # Loop through the list.\n",
    "        if len(words_in_sent) > 0:                                           # Only continue if the length is greater than 0.\n",
    "            len_of_words_in_sent = [len(word) for word in words_in_sent]     # Calculate the Length of words in the Sentence.\n",
    "            avg_word_length = sum(len_of_words_in_sent) / len(len_of_words_in_sent) #Calculate the Average word Length in the sentence.\n",
    "            num_words = len(len_of_words_in_sent)                            # Calculate the number of words in the sentence.\n",
    "            data.append((num_words,round(avg_word_length,2)))                # Return the Number of Words, and the Average Length in a list.\n",
    "    return data\n",
    "\n",
    "####################################################\n",
    "#Call all of the above functions to find the number of words in each sentence, \n",
    "#and the average length of all the words in the sentence.\n",
    "####################################################\n",
    "def collect_statistics(file_name):\n",
    "\n",
    "    read_data = read_file(file_name)\n",
    "    read_data = remove_abbreviations(read_data)\n",
    "    read_data = remove_bad_punct(read_data)\n",
    "    read_data = remove_good_punct(read_data)\n",
    "    read_data = remove_bad_lines(read_data)\n",
    "    read_data = remove_title(read_data)\n",
    "\n",
    "    cleaned_data = read_data\n",
    "\n",
    "    sentence_list = split_into_sentences(cleaned_data)\n",
    "    per_sentence  = split_into_words(sentence_list)\n",
    "    result        = word_length_list2(per_sentence)\n",
    "    \n",
    "    return(result)\n",
    "##################################################\n",
    "\n",
    "#Call the main function with the file name\n",
    "data_list = collect_statistics('pride.txt')\n",
    "\n",
    "#Write the File name provided of the give dataset from above.\n",
    "write_file('pride_summary.txt',data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 2.  Introduction \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/English_letter_frequency_%28alphabetic%29.svg/600px-English_letter_frequency_%28alphabetic%29.svg.png\" width=\"300\">\n",
    "\n",
    "Here we will be counting e's in text files, capitalized and uncapitalized, and accented and unaccented.\n",
    "\n",
    "ðŸŽ¯ Your code in 2(b) must include a function called \n",
    "```\n",
    "    count_letter_e(filename, ignore_accents, ignore_case)\n",
    "    ```\n",
    "    \n",
    "  That is, `count_letter_e`:\n",
    "  * takes a filename, such as ```\"pg1342.txt\"```, as input, and \n",
    "  * returns the number of _e_'s as output. \n",
    "  * includes two optional arguments, ```ignore_accents``` and ```ignore_case```.\n",
    "    * When ```ignore_accents = True```, your function should count accented characters such as _Ã©_, _Ãª_, and _Ã¨_ as the same as _e_.  \n",
    "    * When ```ignore_case=True```, your function should treat uppercase and lowercase _e_ as the same letter.\n",
    "* The function ```count_letter_e()``` should return a *single number*, the total number of all characters that are being treated as equivalent to _e_.\n",
    "* Create other functions as necessary to organize your work.\n",
    "* Include comments which explain the purpose and arguments of each function you create.\n",
    "* The files are encoded as [utf-8](https://en.wikipedia.org/wiki/UTF-8). When reading the files, you may have to specify the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open File with utf-8\n",
    "def read_file(in_name):\n",
    "    with open(in_name,'r',encoding=\"utf-8\") as f:\n",
    "        out_data = f.read()\n",
    "    f.closed\n",
    "    return out_data\n",
    "\n",
    "#Replace lower case accents such as _Ã©_, _Ãª_, and _Ã¨_ to \"_e_\".\n",
    "def replace_lower_e_punct(in_data):\n",
    "    out_data = in_data.replace('Ã©',\"e\").replace('Ãª',\"e\").replace('Ã¨',\"e\").replace('Ã«',\"e\")\n",
    "    return out_data\n",
    "\n",
    "#Replace upper case accents such as _Ã©_, _Ãª_, and _Ã¨_ to \"_e_\".\n",
    "def replace_upper_e_punct(in_data2):\n",
    "    out_data2 = in_data2.replace('Ã‰',\"e\").replace('ÃŠ',\"e\").replace('Ãˆ',\"e\").replace('Ã‹',\"e\").replace('E',\"e\").replace('Ãˆ',\"e\")\n",
    "    return out_data2\n",
    "\n",
    "#Count the number of '_e_' in the data.\n",
    "def count_letters(in_word):\n",
    "    return in_word.count('e')\n",
    "\n",
    "#\n",
    "def count_letter_e(filename, ignore_accents, ignore_case):\n",
    "    file_data = read_file(filename)\n",
    "    \n",
    "    if ignore_case=='True':\n",
    "        file_data = replace_upper_e_punct(file_data)\n",
    "        file_data = replace_lower_e_punct(file_data)\n",
    "        \n",
    "    if ignore_accents=='True':\n",
    "        file_data = replace_lower_e_punct(file_data)\n",
    "    \n",
    "    return_count = count_letters(file_data)\n",
    "    \n",
    "    return return_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 2(a).  Design a Test Suite\n",
    "\n",
    "ðŸŽ¯ Design a test suite (which will be in this case a set of input text) of at least four sentences that will allow you to quickly verify that all four optional argument possibilities are implemented correctly. Make sure that your test suite contains at least one of each of the 8 possible e's (e, Ã©, Ãª, Ã¨, E, Ã‰, ÃŠ, Ãˆ).\n",
    "\n",
    "ðŸŽ¯ Save your test suite as a set of text files (1 sentence per text file) for use in your ```count_letter_e()``` function, and also include each test sentence in a different markdown cell below. For each sentence, count each type of e by hand and report (in the markdown cell) what the output should be for the four possible combinations of true and false for ```ignore_case``` and ```ignore_accents```.\n",
    "\n",
    "*Note that you can complete this portion before you have written a single line of code for your function ```count_letter_e()```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 1:\n",
    "  * Sentence: \n",
    "  * Count with `ignore_case=True, ignore_accents=True`:\n",
    "  * Count with `ignore_case=True, ignore_accents=False`:\n",
    "  * Count with `ignore_case=False, ignore_accents=True`:\n",
    "  * Count with `ignore_case=False, ignore_accents=False`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sentence 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¯ Describe how you can use your four test sentences to detect problems in your implementation of `count_letter_e()`.  Why do you need four sentences, and not just one, or as many as 16?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2(b). Create and Test Your Code\n",
    "\n",
    "ðŸŽ¯ Create the functions described in Problem 2 Introduction, and apply them to your test suite from 2(a).  Do *not* use \n",
    "Python packages or code directly copied from online resources.  Write your own functions from first principles.\n",
    "\n",
    "ðŸŽ¯ Print the results of applying the four combinations of optional arguments of your ```count_letter_e()``` function to your test suite. Verify that the output is correct. (If it isn't, modify your code until your function works correctly on your test suite.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_1.txt\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "test_2.txt\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "test_3.txt\n",
      "26\n",
      "25\n",
      "26\n",
      "20\n",
      "test_4.txt\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def test_count_letter_e(file_in):\n",
    "    print(file_in)\n",
    "    return_count = count_letter_e(file_in,'True','True')\n",
    "    print(return_count)\n",
    "\n",
    "    return_count = count_letter_e(file_in,'True','False')\n",
    "    print(return_count)\n",
    "\n",
    "    return_count = count_letter_e(file_in,'False','True')\n",
    "    print(return_count)\n",
    "\n",
    "    return_count = count_letter_e(file_in,'False','False')\n",
    "    print(return_count)\n",
    "    return\n",
    "\n",
    "#Test sentence 1:  \n",
    "#Sentence: L'ENLÃˆVEMENT DE LA REDOUTE\n",
    "test_count_letter_e('test_1.txt')\n",
    "\n",
    "#Test sentence 2:\n",
    "#Sentence: Je rejoignis le rÃ©giment le 4 septembre au soir.\n",
    "test_count_letter_e('test_2.txt')\n",
    "\n",
    "#Test sentence 3:\n",
    "#Sentence: Elles commencÃ¨rent un feu trÃ¨s vif sur l'ennemi, qui riposta Ã©nergiquement, et bientÃ´t la redoute de Cheverino disparut sous des nuages Ã©pais de fumÃ©e.\n",
    "test_count_letter_e('test_3.txt')\n",
    "\n",
    "#Test sentence 4:\n",
    "#Sentence: Colonel, lui dis-je, vous Ãªtes griÃ¨vement blessÃ©?\n",
    "test_count_letter_e('test_4.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2(c). Apply Your Code\n",
    "\n",
    "ðŸŽ¯ Apply your code from 2(b) to the two provided `.txt` files for _Pride and Prejudice_  and _L'EnlÃ¨vement de la redoute_. \n",
    "ðŸŽ¯ For each file, print the output of all four combinations of the boolena arguments to `count_letter_e`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenlevement.txt\n",
      "1486\n",
      "1469\n",
      "1486\n",
      "1273\n",
      "pride.txt\n",
      "69372\n",
      "68641\n",
      "69372\n",
      "68641\n"
     ]
    }
   ],
   "source": [
    "#Test sentence 4:\n",
    "#Sentence: lenlevement.txt\n",
    "test_count_letter_e('lenlevement.txt')\n",
    "\n",
    "#Test sentence 5:\n",
    "#Sentence: pride.txt\n",
    "test_count_letter_e('pride.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
